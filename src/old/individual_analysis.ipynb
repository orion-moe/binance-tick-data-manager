{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset_path = '../datasets/BTCUSDT-Trades/'\n",
    "output_path = '../output'\n",
    "output_base_path = '../output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trade_id</th>\n",
       "      <th>price</th>\n",
       "      <th>qty</th>\n",
       "      <th>quoteQty</th>\n",
       "      <th>time</th>\n",
       "      <th>isBuyerMaker</th>\n",
       "      <th>isBestMatch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>426.148000</td>\n",
       "      <td>2017-08-17 04:00:28.322</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>6818.368000</td>\n",
       "      <td>2017-08-17 04:00:32.285</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>0.075183</td>\n",
       "      <td>320.390851</td>\n",
       "      <td>2017-08-17 04:00:32.322</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4280.56</td>\n",
       "      <td>0.029600</td>\n",
       "      <td>126.704576</td>\n",
       "      <td>2017-08-17 04:02:48.879</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4280.56</td>\n",
       "      <td>0.231474</td>\n",
       "      <td>990.838345</td>\n",
       "      <td>2017-08-17 04:02:48.887</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trade_id    price       qty     quoteQty                    time  \\\n",
       "0         0  4261.48  0.100000   426.148000 2017-08-17 04:00:28.322   \n",
       "1         1  4261.48  1.600000  6818.368000 2017-08-17 04:00:32.285   \n",
       "2         2  4261.48  0.075183   320.390851 2017-08-17 04:00:32.322   \n",
       "3         3  4280.56  0.029600   126.704576 2017-08-17 04:02:48.879   \n",
       "4         4  4280.56  0.231474   990.838345 2017-08-17 04:02:48.887   \n",
       "\n",
       "   isBuyerMaker  isBestMatch  \n",
       "0          True         True  \n",
       "1          True         True  \n",
       "2         False         True  \n",
       "3         False         True  \n",
       "4         False         True  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from loguru import logger\n",
    "import dask.dataframe as dd\n",
    "from dask.diagnostics import ProgressBar\n",
    "import pandas as pd\n",
    "\n",
    "logger.remove()\n",
    "logger.add(lambda msg: print(msg, end=\"\"), level=\"INFO\")\n",
    "\n",
    "from utils import create_dollar_bars\n",
    "\n",
    "df_dask = dd.read_parquet(os.path.join(raw_dataset_path, 'BTCUSDT-Dataset-part-1.parquet'), columns=[])\n",
    "\n",
    "df_dask.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.600000\n",
       "1    0.075183\n",
       "2    0.029600\n",
       "3    0.231474\n",
       "4    0.000234\n",
       "Name: qty, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dask['qty'].shift(-1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['side'] = np.where(df['price'].shift() > df['price'], 1, np.where(df['price'].shift() < df['price'], -1, np.nan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Client: 'tcp://127.0.0.1:56878' processes=4 threads=12, memory=29.80 GiB>\n",
      "Dask DataFrame Structure:\n",
      "                   price      qty quoteQty            time\n",
      "npartitions=469                                           \n",
      "                 float64  float64  float64  datetime64[ns]\n",
      "                     ...      ...      ...             ...\n",
      "...                  ...      ...      ...             ...\n",
      "                     ...      ...      ...             ...\n",
      "                     ...      ...      ...             ...\n",
      "Dask Name: read_parquet, 1 expression\n",
      "Expr=ReadParquetFSSpec(b98da6b)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "# Configuração do cluster Dask com limite de memória de 32 GB\n",
    "cluster = LocalCluster(\n",
    "    n_workers=4,            # Número de workers; ajuste conforme seu hardware\n",
    "    threads_per_worker=3,   # Threads por worker\n",
    "    memory_limit='8GB'      # Memória por worker (4 workers x 8GB = 32GB)\n",
    ")\n",
    "client = Client(cluster)\n",
    "\n",
    "print(client)\n",
    "\n",
    "# Padrão para ler todos os arquivos Parquet\n",
    "parquet_pattern = os.path.join(raw_dataset_path, 'BTCUSDT-Dataset-part-*.parquet')\n",
    "\n",
    "# Leitura dos arquivos Parquet com Dask\n",
    "df_dask = dd.read_parquet(parquet_pattern, columns=['price', 'qty', 'quoteQty', 'time'])\n",
    "\n",
    "print(df_dask)\n",
    "\n",
    "# Encerrar o cliente Dask após a conclusão\n",
    "client.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de núcleos disponíveis: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 56908 instead\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/dask_expr/_collection.py:4160: UserWarning: \n",
      "You did not provide metadata, so Dask is running your function on a small dataset to guess output types. It is possible that Dask will guess incorrectly.\n",
      "To provide an explicit output types or to silence this message, please provide the `meta=` keyword, as described in the map or apply function that you are using.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta=('isBuyerMaker', 'int64'))\n",
      "\n",
      "  warnings.warn(meta_warning(meta))\n",
      "2024-12-21 16:52:38,376 - distributed.protocol.core - CRITICAL - Failed to deserialize\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/msgpack/fallback.py\", line 128, in unpackb\n",
      "    ret = unpacker._unpack()\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/msgpack/fallback.py\", line 565, in _unpack\n",
      "    ret.append(self._unpack(EX_CONSTRUCT))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/msgpack/fallback.py\", line 585, in _unpack\n",
      "    key = self._unpack(EX_CONSTRUCT)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/msgpack/fallback.py\", line 546, in _unpack\n",
      "    typ, n, obj = self._read_header()\n",
      "                  ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/msgpack/fallback.py\", line 447, in _read_header\n",
      "    self._reserve(1)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/msgpack/fallback.py\", line 420, in _reserve\n",
      "    raise OutOfData\n",
      "msgpack.exceptions.OutOfData\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/distributed/protocol/core.py\", line 175, in loads\n",
      "    return msgpack.loads(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/msgpack/fallback.py\", line 130, in unpackb\n",
      "    raise ValueError(\"Unpack failed: incomplete input\")\n",
      "ValueError: Unpack failed: incomplete input\n",
      "2024-12-21 16:52:38,378 - distributed.core - ERROR - Exception while handling op register-client\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/msgpack/fallback.py\", line 128, in unpackb\n",
      "    ret = unpacker._unpack()\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/msgpack/fallback.py\", line 565, in _unpack\n",
      "    ret.append(self._unpack(EX_CONSTRUCT))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/msgpack/fallback.py\", line 585, in _unpack\n",
      "    key = self._unpack(EX_CONSTRUCT)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/msgpack/fallback.py\", line 546, in _unpack\n",
      "    typ, n, obj = self._read_header()\n",
      "                  ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/msgpack/fallback.py\", line 447, in _read_header\n",
      "    self._reserve(1)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/msgpack/fallback.py\", line 420, in _reserve\n",
      "    raise OutOfData\n",
      "msgpack.exceptions.OutOfData\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/distributed/core.py\", line 970, in _handle_comm\n",
      "    result = await result\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/distributed/scheduler.py\", line 5710, in add_client\n",
      "    await self.handle_stream(comm=comm, extra={\"client\": client})\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/distributed/core.py\", line 1025, in handle_stream\n",
      "    msgs = await comm.read()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 247, in read\n",
      "    msg = await from_frames(\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/distributed/comm/utils.py\", line 78, in from_frames\n",
      "    res = _from_frames()\n",
      "          ^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/distributed/comm/utils.py\", line 61, in _from_frames\n",
      "    return protocol.loads(\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/distributed/protocol/core.py\", line 175, in loads\n",
      "    return msgpack.loads(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/msgpack/fallback.py\", line 130, in unpackb\n",
      "    raise ValueError(\"Unpack failed: incomplete input\")\n",
      "ValueError: Unpack failed: incomplete input\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1344' coro=<Server._handle_comm() done, defined at /opt/anaconda3/lib/python3.12/site-packages/distributed/core.py:876> exception=ValueError('Unpack failed: incomplete input')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/msgpack/fallback.py\", line 128, in unpackb\n",
      "    ret = unpacker._unpack()\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/msgpack/fallback.py\", line 565, in _unpack\n",
      "    ret.append(self._unpack(EX_CONSTRUCT))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/msgpack/fallback.py\", line 585, in _unpack\n",
      "    key = self._unpack(EX_CONSTRUCT)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/msgpack/fallback.py\", line 546, in _unpack\n",
      "    typ, n, obj = self._read_header()\n",
      "                  ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/msgpack/fallback.py\", line 447, in _read_header\n",
      "    self._reserve(1)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/msgpack/fallback.py\", line 420, in _reserve\n",
      "    raise OutOfData\n",
      "msgpack.exceptions.OutOfData\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/distributed/core.py\", line 970, in _handle_comm\n",
      "    result = await result\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/distributed/scheduler.py\", line 5710, in add_client\n",
      "    await self.handle_stream(comm=comm, extra={\"client\": client})\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/distributed/core.py\", line 1025, in handle_stream\n",
      "    msgs = await comm.read()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 247, in read\n",
      "    msg = await from_frames(\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/distributed/comm/utils.py\", line 78, in from_frames\n",
      "    res = _from_frames()\n",
      "          ^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/distributed/comm/utils.py\", line 61, in _from_frames\n",
      "    return protocol.loads(\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/distributed/protocol/core.py\", line 175, in loads\n",
      "    return msgpack.loads(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/msgpack/fallback.py\", line 130, in unpackb\n",
      "    raise ValueError(\"Unpack failed: incomplete input\")\n",
      "ValueError: Unpack failed: incomplete input\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Client: 'tcp://127.0.0.1:56909' processes=2 threads=8, memory=14.90 GiB>\n",
      "Arquivos Parquet lidos com sucesso.\n",
      "Operações matemáticas aplicadas com sucesso.\n",
      "Erro durante a computação das métricas: ('mean_aggregate-639fbc2a14536e703350db49f712e37b', 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-21 16:52:42,114 - distributed.protocol.core - CRITICAL - Failed to deserialize\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/msgpack/fallback.py\", line 128, in unpackb\n",
      "    ret = unpacker._unpack()\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/msgpack/fallback.py\", line 565, in _unpack\n",
      "    ret.append(self._unpack(EX_CONSTRUCT))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/msgpack/fallback.py\", line 585, in _unpack\n",
      "    key = self._unpack(EX_CONSTRUCT)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/msgpack/fallback.py\", line 546, in _unpack\n",
      "    typ, n, obj = self._read_header()\n",
      "                  ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/msgpack/fallback.py\", line 447, in _read_header\n",
      "    self._reserve(1)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/msgpack/fallback.py\", line 420, in _reserve\n",
      "    raise OutOfData\n",
      "msgpack.exceptions.OutOfData\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/distributed/protocol/core.py\", line 175, in loads\n",
      "    return msgpack.loads(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/msgpack/fallback.py\", line 130, in unpackb\n",
      "    raise ValueError(\"Unpack failed: incomplete input\")\n",
      "ValueError: Unpack failed: incomplete input\n",
      "2024-12-21 16:52:42,115 - distributed.core - ERROR - Exception while handling op register-client\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/msgpack/fallback.py\", line 128, in unpackb\n",
      "    ret = unpacker._unpack()\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/msgpack/fallback.py\", line 565, in _unpack\n",
      "    ret.append(self._unpack(EX_CONSTRUCT))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/msgpack/fallback.py\", line 585, in _unpack\n",
      "    key = self._unpack(EX_CONSTRUCT)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/msgpack/fallback.py\", line 546, in _unpack\n",
      "    typ, n, obj = self._read_header()\n",
      "                  ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/msgpack/fallback.py\", line 447, in _read_header\n",
      "    self._reserve(1)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/msgpack/fallback.py\", line 420, in _reserve\n",
      "    raise OutOfData\n",
      "msgpack.exceptions.OutOfData\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/distributed/core.py\", line 970, in _handle_comm\n",
      "    result = await result\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/distributed/scheduler.py\", line 5710, in add_client\n",
      "    await self.handle_stream(comm=comm, extra={\"client\": client})\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/distributed/core.py\", line 1025, in handle_stream\n",
      "    msgs = await comm.read()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 247, in read\n",
      "    msg = await from_frames(\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/distributed/comm/utils.py\", line 78, in from_frames\n",
      "    res = _from_frames()\n",
      "          ^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/distributed/comm/utils.py\", line 61, in _from_frames\n",
      "    return protocol.loads(\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/distributed/protocol/core.py\", line 175, in loads\n",
      "    return msgpack.loads(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/msgpack/fallback.py\", line 130, in unpackb\n",
      "    raise ValueError(\"Unpack failed: incomplete input\")\n",
      "ValueError: Unpack failed: incomplete input\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1405' coro=<Server._handle_comm() done, defined at /opt/anaconda3/lib/python3.12/site-packages/distributed/core.py:876> exception=ValueError('Unpack failed: incomplete input')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/msgpack/fallback.py\", line 128, in unpackb\n",
      "    ret = unpacker._unpack()\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/msgpack/fallback.py\", line 565, in _unpack\n",
      "    ret.append(self._unpack(EX_CONSTRUCT))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/msgpack/fallback.py\", line 585, in _unpack\n",
      "    key = self._unpack(EX_CONSTRUCT)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/msgpack/fallback.py\", line 546, in _unpack\n",
      "    typ, n, obj = self._read_header()\n",
      "                  ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/msgpack/fallback.py\", line 447, in _read_header\n",
      "    self._reserve(1)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/msgpack/fallback.py\", line 420, in _reserve\n",
      "    raise OutOfData\n",
      "msgpack.exceptions.OutOfData\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/distributed/core.py\", line 970, in _handle_comm\n",
      "    result = await result\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/distributed/scheduler.py\", line 5710, in add_client\n",
      "    await self.handle_stream(comm=comm, extra={\"client\": client})\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/distributed/core.py\", line 1025, in handle_stream\n",
      "    msgs = await comm.read()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 247, in read\n",
      "    msg = await from_frames(\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/distributed/comm/utils.py\", line 78, in from_frames\n",
      "    res = _from_frames()\n",
      "          ^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/distributed/comm/utils.py\", line 61, in _from_frames\n",
      "    return protocol.loads(\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/distributed/protocol/core.py\", line 175, in loads\n",
      "    return msgpack.loads(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/msgpack/fallback.py\", line 130, in unpackb\n",
      "    raise ValueError(\"Unpack failed: incomplete input\")\n",
      "ValueError: Unpack failed: incomplete input\n",
      "2024-12-21 16:52:42,225 - distributed.client - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/distributed/utils.py\", line 832, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/distributed/client.py\", line 1330, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/distributed/client.py\", line 1360, in _ensure_connected\n",
      "    comm = await connect(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/distributed/comm/core.py\", line 342, in connect\n",
      "    comm = await wait_for(\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/distributed/utils.py\", line 1956, in wait_for\n",
      "    return await fut\n",
      "           ^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 546, in connect\n",
      "    stream = await self.client.connect(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/tornado/tcpclient.py\", line 279, in connect\n",
      "    af, addr, stream = await connector.start(connect_timeout=timeout)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "asyncio.exceptions.CancelledError\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro ao salvar o DataFrame: ('toparquetbarrier-4c954778084d6eadccce89538bd1241b', 0)\n",
      "Erro ao validar os dados salvos: No files satisfy the `parquet_file_extension` criteria (files must end with ('.parq', '.parquet', '.pq')).\n",
      "Cliente Dask encerrado.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client, LocalCluster\n",
    "import multiprocessing\n",
    "import datetime\n",
    "\n",
    "# 1. Configuração do Cluster Dask com ajustes para otimização de memória\n",
    "def setup_dask_cluster():\n",
    "    num_cores = multiprocessing.cpu_count()\n",
    "    print(f\"Número de núcleos disponíveis: {num_cores}\")\n",
    "\n",
    "    # Definindo número de workers e threads por worker\n",
    "    # Ajuste conforme seu sistema e necessidades\n",
    "    # Por exemplo, 8 núcleos: 2 workers com 4 threads cada\n",
    "    n_workers = 2  # Reduzido para menos workers\n",
    "    threads_per_worker = 4  # Mais threads por worker\n",
    "\n",
    "    cluster = LocalCluster(\n",
    "        n_workers=n_workers,\n",
    "        threads_per_worker=threads_per_worker,\n",
    "        memory_limit='8GB'  # Ajuste a memória por worker conforme necessário\n",
    "    )\n",
    "\n",
    "    client = Client(cluster)\n",
    "    print(client)\n",
    "    return client\n",
    "\n",
    "# 2. Leitura dos Arquivos Parquet com otimização de memória\n",
    "def read_parquet_files(raw_dataset_path):\n",
    "    parquet_pattern = os.path.join(raw_dataset_path, 'BTCUSDT-Dataset-part-*.parquet')\n",
    "    # Especifique apenas as colunas necessárias e otimize os tipos de dados se possível\n",
    "    df_dask = dd.read_parquet(\n",
    "        parquet_pattern,\n",
    "        columns=['price', 'qty', 'isBuyerMaker', 'time'],\n",
    "        engine='pyarrow'  # Utilize o engine 'pyarrow' para melhor performance\n",
    "    )\n",
    "    return df_dask\n",
    "\n",
    "# 3. Aplicação das Operações Matemáticas\n",
    "def apply_operations(df_dask):\n",
    "    # Calcular 'trade_dollar' = price * qty\n",
    "    df_dask['trade_dollar'] = df_dask['price'] * df_dask['qty']\n",
    "\n",
    "    # Calcular 'dollar_side' = -1 se isBuyerMaker for True, 1 se False\n",
    "    df_dask['dollar_side'] = df_dask['isBuyerMaker'].map({True: -1, False: 1})\n",
    "\n",
    "    # Calcular 'dollar_imbalance' = trade_dollar * dollar_side\n",
    "    df_dask['dollar_imbalance'] = df_dask['trade_dollar'] * df_dask['dollar_side']\n",
    "\n",
    "    return df_dask\n",
    "\n",
    "# 4. Salvar o DataFrame Processado\n",
    "def save_processed_dataframe(df_dask, output_path):\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    try:\n",
    "        df_dask.to_parquet(\n",
    "            output_path,\n",
    "            write_index=False,\n",
    "            compression='snappy',\n",
    "            partition_size='500MB',  # Reduzido para partições menores\n",
    "            overwrite=True\n",
    "        )\n",
    "        print(f\"DataFrame processado salvo com sucesso em: {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao salvar o DataFrame: {e}\")\n",
    "\n",
    "# 5. Função Principal para Orquestrar o Processo\n",
    "def main():\n",
    "\n",
    "\n",
    "    # Configuração do Cluster\n",
    "    client = setup_dask_cluster()\n",
    "\n",
    "    try:\n",
    "        # Leitura dos Arquivos\n",
    "        df_dask = read_parquet_files(raw_dataset_path)\n",
    "        print(\"Arquivos Parquet lidos com sucesso.\")\n",
    "\n",
    "        # Aplicação das Operações Matemáticas\n",
    "        df_dask = apply_operations(df_dask)\n",
    "        print(\"Operações matemáticas aplicadas com sucesso.\")\n",
    "\n",
    "        # Opcional: Persistir os dados na memória para otimizar múltiplas operações\n",
    "        # df_dask = df_dask.persist()\n",
    "\n",
    "        # Cálculo de Métricas\n",
    "        media_preco = df_dask['price'].mean()\n",
    "        total_dollar_imbalance = df_dask['dollar_imbalance'].sum()\n",
    "        df_filtrado = df_dask[df_dask['qty'] > 1000]\n",
    "\n",
    "        # Executar o processamento com tratamento de erros\n",
    "        try:\n",
    "            resultado_media_preco = media_preco.compute()\n",
    "            resultado_total_dollar_imbalance = total_dollar_imbalance.compute()\n",
    "            resultado_df_filtrado = df_filtrado.compute()\n",
    "\n",
    "            print(f\"Média do preço: {resultado_media_preco}\")\n",
    "            print(f\"Total do dollar imbalance: {resultado_total_dollar_imbalance}\")\n",
    "            print(\"DataFrame filtrado (exemplo):\")\n",
    "            print(resultado_df_filtrado.head())\n",
    "        except Exception as compute_error:\n",
    "            print(f\"Erro durante a computação das métricas: {compute_error}\")\n",
    "\n",
    "        # Definir Caminho de Saída com Versionamento\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        output_path = f'{output_base_path}_v{timestamp}'\n",
    "\n",
    "        # Salvar o DataFrame Processado\n",
    "        save_processed_dataframe(df_dask, output_path)\n",
    "\n",
    "        # Validação dos Dados Salvos\n",
    "        try:\n",
    "            df_reloaded = dd.read_parquet(output_path)\n",
    "            media_preco_reloaded = df_reloaded['price'].mean().compute()\n",
    "            total_dollar_imbalance_reloaded = df_reloaded['dollar_imbalance'].sum().compute()\n",
    "\n",
    "            print(f\"Média do preço após o salvamento: {media_preco_reloaded}\")\n",
    "            print(f\"Total do dollar imbalance após o salvamento: {total_dollar_imbalance_reloaded}\")\n",
    "        except Exception as validation_error:\n",
    "            print(f\"Erro ao validar os dados salvos: {validation_error}\")\n",
    "\n",
    "    finally:\n",
    "        # Encerrar o Cliente Dask\n",
    "        client.close()\n",
    "        print(\"Cliente Dask encerrado.\")\n",
    "\n",
    "# Executar a Função Principal\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import distributed\n",
    "import pkg_resources\n",
    "\n",
    "print(\"Dask version:\", dask.__version__)\n",
    "print(\"Distributed version:\", distributed.__version__)\n",
    "\n",
    "try:\n",
    "    msgpack_version = pkg_resources.get_distribution(\"msgpack\").version\n",
    "    print(\"msgpack version:\", msgpack_version)\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao obter a versão do msgpack: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Criando um DataFrame de exemplo\n",
    "df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\n",
    "\n",
    "# Deletando o DataFrame\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "# Forçando a coleta de lixo\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
