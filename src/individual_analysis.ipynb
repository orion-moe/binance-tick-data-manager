{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client, LocalCluster\n",
    "import multiprocessing\n",
    "import datetime\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Configurar o logging para visualizar os logs de informação\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset_path = '../datasets/BTCUSDT-Trades/'\n",
    "output_base_path = '../output'\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "output_path = f'{output_base_path}_v{timestamp}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Configuração do Cluster Dask com ajustes para otimização de memória\n",
    "def setup_dask_cluster(n_workers=3, threads_per_worker=4, memory_limit='16GB'):\n",
    "    num_cores = multiprocessing.cpu_count()\n",
    "    print(f\"Número de núcleos disponíveis: {num_cores}\")\n",
    "\n",
    "    cluster = LocalCluster(\n",
    "        n_workers=n_workers,\n",
    "        threads_per_worker=threads_per_worker,\n",
    "        memory_limit=memory_limit\n",
    "    )\n",
    "\n",
    "    client = Client(cluster)\n",
    "    print(client)\n",
    "    return client\n",
    "\n",
    "# 2. Leitura dos Arquivos Parquet com otimização de memória\n",
    "def read_parquet_files(raw_dataset_path, file):\n",
    "    parquet_pattern = os.path.join(raw_dataset_path, file)\n",
    "    df_dask = dd.read_parquet(\n",
    "        parquet_pattern,\n",
    "        columns=['price', 'qty', 'quoteQty', 'time'],\n",
    "        engine='pyarrow'\n",
    "    )\n",
    "\n",
    "    # Otimizar tipos de dados para reduzir uso de memória\n",
    "    df_dask['price'] = df_dask['price'].astype('float32')\n",
    "    df_dask['qty'] = df_dask['qty'].astype('float32')\n",
    "    df_dask['quoteQty'] = df_dask['quoteQty'].astype('float32')\n",
    "    return df_dask\n",
    "\n",
    "# 3. Aplicação das Operações Matemáticas\n",
    "def apply_operations(df_dask):\n",
    "\n",
    "    df_dask['side'] = np.nan\n",
    "\n",
    "    # Calcular 'dollar_side' = -1 se isBuyerMaker for True, 1 se False\n",
    "    df_dask['side'] = np.where(df_dask['quoteQty'].shift() > df_dask['price'], 1, df_dask['side'])\n",
    "\n",
    "    df_dask['side'] = np.where(df_dask['quoteQty'].shift() < df_dask['price'], -1, df_dask['side'])\n",
    "\n",
    "    df_dask.at[0, 'side'] = 1\n",
    "\n",
    "    df_dask['side'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "    # Calcular 'dollar_imbalance' = trade_dollar * dollar_side\n",
    "    df_dask['dollar_imbalance'] = df_dask['trade_dollar'] * df_dask['side']\n",
    "\n",
    "    return df_dask\n",
    "\n",
    "\n",
    "def assign_side(df):\n",
    "    df['side'] = np.nan\n",
    "    df['side'] = np.where(df['price'].shift() > df['price'], 1, df['side'])\n",
    "    df['side'] = np.where(df['price'].shift() < df['price'], -1, df['side'])\n",
    "    df.at[0, 'side'] = 1\n",
    "    df['side'] = df['side'].ffill().astype('int8')\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_imbalance_dollar_bars(df_dask, init_T, init_dif, alpha, res):\n",
    "\n",
    "    exp_T     = init_T\n",
    "    exp_dif   = init_dif\n",
    "    threshold = exp_T * init_dif\n",
    "\n",
    "    bars = []\n",
    "\n",
    "    # Variáveis de agregação de uma barra\n",
    "    if len(res) > 0:\n",
    "        bar_open = res[0]\n",
    "        bar_high = res[1]\n",
    "        bar_low = res[2]\n",
    "        bar_close = res[3]\n",
    "        bar_start_time = res[4]\n",
    "        bar_end_time = res[5]\n",
    "        current_imbalance = res[6]\n",
    "        buy_volume_usd = res[7]\n",
    "        total_volume_usd = res[8]\n",
    "        total_volume = res[9]\n",
    "    else:\n",
    "        bar_open = None\n",
    "        bar_high = -float('inf')\n",
    "        bar_low = float('inf')\n",
    "        bar_close = None\n",
    "        bar_start_time = None\n",
    "        bar_end_time = None\n",
    "        current_imbalance = 0\n",
    "        buy_volume_usd = 0\n",
    "        total_volume_usd = 0\n",
    "        total_volume = 0\n",
    "\n",
    "    price_col = 'price'\n",
    "    time_col = 'time'\n",
    "    imbalance_col = 'dollar_imbalance'\n",
    "    volume_col = 'qty'\n",
    "\n",
    "    try:\n",
    "        # IMPORTANT: df_dask is already a pandas slice at map_partitions-level\n",
    "        # so we can iterate directly over df_dask.iterrows() in local memory for that partition.\n",
    "        for idx, row in df_dask.iterrows():\n",
    "\n",
    "            if bar_open is None:\n",
    "                bar_open = row[price_col]\n",
    "                bar_start_time = row[time_col]\n",
    "\n",
    "            # Atualiza valores de OHLC\n",
    "            trade_price = row[price_col]\n",
    "            bar_high    = max(bar_high, trade_price)\n",
    "            bar_low     = min(bar_low, trade_price)\n",
    "            bar_close   = trade_price\n",
    "\n",
    "\n",
    "            # Soma o volume (ou outra métrica de desequilíbrio)\n",
    "            trade_imbalance = row[imbalance_col]\n",
    "\n",
    "            if row['side'] > 0:\n",
    "                buy_volume_usd += trade_imbalance\n",
    "\n",
    "            total_volume += row[volume_col]\n",
    "            total_volume_usd += abs(trade_imbalance)\n",
    "            current_imbalance += trade_imbalance\n",
    "            imbalance = abs(current_imbalance)\n",
    "            # Verifica se a soma já ultrapassou o threshold\n",
    "            if imbalance >= threshold:\n",
    "                bar_end_time = row[time_col]\n",
    "\n",
    "                # Salvar a barra formada\n",
    "                bars.append({\n",
    "                    'start_time': bar_start_time,\n",
    "                    'end_time': bar_end_time,\n",
    "                    'open': bar_open,\n",
    "                    'high': bar_high,\n",
    "                    'low': bar_low,\n",
    "                    'close': bar_close,\n",
    "                    'imbalance_col': current_imbalance,\n",
    "                    'total_volume_buy_usd': buy_volume_usd,\n",
    "                    'total_volume_usd': total_volume_usd,\n",
    "                    'total_volume': total_volume\n",
    "                })\n",
    "\n",
    "                # pdbar_T = bar_end_time - bar_start_time\n",
    "                # bar_T = pdbar_T.total_seconds()\n",
    "\n",
    "                # Exponential-weighted updates\n",
    "                if exp_dif == 1:\n",
    "                    exp_T   = total_volume_usd\n",
    "                    exp_dif = abs(2 * buy_volume_usd/total_volume_usd - 1)\n",
    "                else:\n",
    "                    exp_T   += alpha * (total_volume_usd   - exp_T)\n",
    "                    exp_dif += alpha * (abs(2 * buy_volume_usd/total_volume_usd - 1) - exp_dif)\n",
    "                # Reset accumulators\n",
    "                threshold = exp_T * exp_dif\n",
    "\n",
    "                # Variáveis de agregação de uma barra\n",
    "                bar_open = None\n",
    "                bar_high = -float('inf')\n",
    "                bar_low = float('inf')\n",
    "                bar_close = None\n",
    "                bar_start_time = None\n",
    "                bar_end_time = None\n",
    "                current_imbalance = 0\n",
    "                buy_volume_usd = 0\n",
    "                total_volume_usd = 0\n",
    "                total_volume = 0\n",
    "    finally:\n",
    "        if current_imbalance == 0:\n",
    "            res = []\n",
    "        else:\n",
    "            res = [bar_open, bar_high, bar_low, bar_close, bar_start_time,\n",
    "                   bar_end_time, current_imbalance, buy_volume_usd, total_volume_usd, total_volume]\n",
    "\n",
    "    return bars, exp_T, exp_dif, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_create_imbalance_dollar_bars(df_dask, init_T, init_dif, res_init, alpha):\n",
    "    results = pd.DataFrame()\n",
    "    # df_dask.npartitions\n",
    "    # Precisamos iterar sobre cada partição em ordem\n",
    "    total = df_dask.npartitions\n",
    "    for i in range(0, total):\n",
    "        print(f'partition {i} of {total-1}')\n",
    "        part = df_dask.get_partition(i)\n",
    "\n",
    "        df_part = part.compute()\n",
    "\n",
    "        # processamos essa partição localmente\n",
    "        df_proc, exp_T, exp_dif, res = create_imbalance_dollar_bars(df_part, init_T=init_T, init_dif=init_dif, alpha=alpha, res=res_init)\n",
    "        df_proc = pd.DataFrame(df_proc)\n",
    "        results = pd.concat([results, df_proc])\n",
    "        init_T = exp_T  # passagem do estado final para a próxima partição\n",
    "        init_dif = exp_dif\n",
    "        res_init = res\n",
    "    return results, init_T, init_dif, res_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dask n1 of 37\n",
      "partition 0 of 14\n",
      "partition 1 of 14\n",
      "partition 2 of 14\n",
      "partition 3 of 14\n",
      "partition 4 of 14\n",
      "partition 5 of 14\n",
      "partition 6 of 14\n",
      "partition 7 of 14\n",
      "partition 8 of 14\n",
      "partition 9 of 14\n",
      "partition 10 of 14\n",
      "partition 11 of 14\n",
      "partition 12 of 14\n",
      "partition 13 of 14\n",
      "partition 14 of 14\n",
      "Dask n2 of 37\n",
      "partition 0 of 14\n",
      "partition 1 of 14\n",
      "partition 2 of 14\n",
      "partition 3 of 14\n",
      "partition 4 of 14\n",
      "partition 5 of 14\n",
      "partition 6 of 14\n",
      "partition 7 of 14\n",
      "partition 8 of 14\n",
      "partition 9 of 14\n",
      "partition 10 of 14\n",
      "partition 11 of 14\n",
      "partition 12 of 14\n",
      "partition 13 of 14\n",
      "partition 14 of 14\n",
      "Dask n3 of 37\n",
      "partition 0 of 14\n",
      "partition 1 of 14\n",
      "partition 2 of 14\n",
      "partition 3 of 14\n",
      "partition 4 of 14\n",
      "partition 5 of 14\n",
      "partition 6 of 14\n",
      "partition 7 of 14\n",
      "partition 8 of 14\n",
      "partition 9 of 14\n",
      "partition 10 of 14\n",
      "partition 11 of 14\n",
      "partition 12 of 14\n",
      "partition 13 of 14\n",
      "partition 14 of 14\n",
      "Dask n4 of 37\n",
      "partition 0 of 13\n",
      "partition 1 of 13\n",
      "partition 2 of 13\n",
      "partition 3 of 13\n",
      "partition 4 of 13\n",
      "partition 5 of 13\n",
      "partition 6 of 13\n",
      "partition 7 of 13\n",
      "partition 8 of 13\n",
      "partition 9 of 13\n",
      "partition 10 of 13\n",
      "partition 11 of 13\n",
      "partition 12 of 13\n",
      "partition 13 of 13\n",
      "Dask n5 of 37\n",
      "partition 0 of 13\n",
      "partition 1 of 13\n",
      "partition 2 of 13\n",
      "partition 3 of 13\n",
      "partition 4 of 13\n",
      "partition 5 of 13\n",
      "partition 6 of 13\n",
      "partition 7 of 13\n",
      "partition 8 of 13\n",
      "partition 9 of 13\n",
      "partition 10 of 13\n",
      "partition 11 of 13\n",
      "partition 12 of 13\n",
      "partition 13 of 13\n",
      "Dask n6 of 37\n",
      "partition 0 of 14\n",
      "partition 1 of 14\n",
      "partition 2 of 14\n",
      "partition 3 of 14\n",
      "partition 4 of 14\n",
      "partition 5 of 14\n",
      "partition 6 of 14\n",
      "partition 7 of 14\n",
      "partition 8 of 14\n",
      "partition 9 of 14\n",
      "partition 10 of 14\n",
      "partition 11 of 14\n",
      "partition 12 of 14\n",
      "partition 13 of 14\n",
      "partition 14 of 14\n",
      "Dask n7 of 37\n",
      "partition 0 of 14\n",
      "partition 1 of 14\n",
      "partition 2 of 14\n",
      "partition 3 of 14\n",
      "partition 4 of 14\n",
      "partition 5 of 14\n",
      "partition 6 of 14\n",
      "partition 7 of 14\n",
      "partition 8 of 14\n",
      "partition 9 of 14\n",
      "partition 10 of 14\n",
      "partition 11 of 14\n",
      "partition 12 of 14\n",
      "partition 13 of 14\n",
      "partition 14 of 14\n",
      "Dask n8 of 37\n",
      "partition 0 of 13\n",
      "partition 1 of 13\n",
      "partition 2 of 13\n",
      "partition 3 of 13\n",
      "partition 4 of 13\n",
      "partition 5 of 13\n",
      "partition 6 of 13\n",
      "partition 7 of 13\n",
      "partition 8 of 13\n",
      "partition 9 of 13\n",
      "partition 10 of 13\n",
      "partition 11 of 13\n",
      "partition 12 of 13\n",
      "partition 13 of 13\n",
      "Dask n9 of 37\n",
      "partition 0 of 14\n",
      "partition 1 of 14\n",
      "partition 2 of 14\n",
      "partition 3 of 14\n",
      "partition 4 of 14\n",
      "partition 5 of 14\n"
     ]
    }
   ],
   "source": [
    "# Liste todos os arquivos e pastas no diretório\n",
    "files = os.listdir(raw_dataset_path)\n",
    "\n",
    "# Filtre apenas os arquivos\n",
    "file_count = sum(1 for f in files if os.path.isfile(os.path.join(raw_dataset_path, f)))\n",
    "\n",
    "results = pd.DataFrame()\n",
    "\n",
    "init_T = 10_000\n",
    "init_dif = 1\n",
    "alpha = 0.1\n",
    "res = []\n",
    "# file_count\n",
    "for number in range(1, file_count):\n",
    "    print(f\"Dask n{number} of {file_count-1}\")\n",
    "\n",
    "    file = 'BTCUSDT-Dataset-part-' + str(number) + '.parquet'\n",
    "\n",
    "    df_dask = read_parquet_files(raw_dataset_path, file)\n",
    "\n",
    "    df_dask = df_dask.map_partitions(assign_side)\n",
    "\n",
    "    df_dask['dollar_imbalance'] = df_dask['quoteQty'] * df_dask['side']\n",
    "    bars, init_T, init_dif, res = batch_create_imbalance_dollar_bars(df_dask, init_T, init_dif, res, alpha)\n",
    "\n",
    "    results = pd.concat([results, bars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = f'{output_path}-{alpha}-{init_T}.xlsx'\n",
    "results.to_excel(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "df = results.copy()\n",
    "df['end_time'] = pd.to_datetime(df['end_time'])\n",
    "\n",
    "# Criando o gráfico de candlestick\n",
    "fig = go.Figure(data=[go.Candlestick(x=df['end_time'],\n",
    "                                       open=df['open'],\n",
    "                                       high=df['high'],\n",
    "                                       low=df['low'],\n",
    "                                       close=df['close'])])\n",
    "\n",
    "# Adicionando título e rótulos\n",
    "fig.update_layout(title='Gráfico de Candlestick',\n",
    "                  xaxis_title='Data',\n",
    "                  yaxis_title='Preço',\n",
    "                  xaxis_rangeslider_visible=False)\n",
    "\n",
    "# Exibindo o gráfico\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mplfinance as mpf\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "matplotlib.use('TkAgg')  # Ou outro backend interativo\n",
    "\n",
    "df = results.copy()\n",
    "\n",
    "# Convertendo a coluna 'start_time' para o índice do DataFrame\n",
    "df['end_time'] = pd.to_datetime(df['end_time'])\n",
    "df.set_index('end_time', inplace=True)\n",
    "\n",
    "# Selecionando apenas as colunas necessárias para o mplfinance\n",
    "df = df[['open', 'high', 'low', 'close']]\n",
    "\n",
    "# Renomeando as colunas para um formato mais amigável\n",
    "df.rename(columns={\n",
    "    'open': 'Open',\n",
    "    'high': 'High',\n",
    "    'low': 'Low',\n",
    "    'close': 'Close'\n",
    "}, inplace=True)\n",
    "\n",
    "\n",
    "# Plotando o gráfico OHLC em preto e branco\n",
    "fig, ax = mpf.plot(df, type='candle', title='Gráfico OHLC', volume=False, show_nontrading=False)\n",
    "\n",
    "# Configurando a escala logarítmica\n",
    "ax[0].set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "df = results.copy()\n",
    "\n",
    "df['end_time'] = pd.to_datetime(df['end_time'])\n",
    "\n",
    "# Criando uma nova coluna com data e hora formatadas como strings (YYYY-MM-DD HH:MM:SS%S)\n",
    "df['end_time_str'] = df['end_time'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "\n",
    "# Criando o gráfico de candlestick\n",
    "fig = go.Figure(data=[go.Candlestick(x=df['end_time_str'],\n",
    "                                       open=df['open'],\n",
    "                                       high=df['high'],\n",
    "                                       low=df['low'],\n",
    "                                       close=df['close'],\n",
    "                                       increasing_line_color='slateblue',\n",
    "                                       decreasing_line_color='black')])\n",
    "\n",
    "# Adicionando título e rótulos\n",
    "fig.update_layout(title='Gráfico de Candlestick',\n",
    "                  xaxis_title='Data',\n",
    "                  yaxis_title='Preço',\n",
    "                  xaxis_rangeslider_visible=True,\n",
    "                  plot_bgcolor='white',\n",
    "                  paper_bgcolor='whitesmoke')\n",
    "\n",
    "\n",
    "fig.update_xaxes(type='category', tickangle=-45)\n",
    "\n",
    "fig.update_yaxes(\n",
    "    type='log',\n",
    "    tickmode='auto'# Escala logarítmica\n",
    ")\n",
    "\n",
    "# Exibindo o gráfico\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
